{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import dgl\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPIC_NOUN_CLASS = 352\n",
    "NUM_EPIC_VERB_CLASS = 125\n",
    "KEY_EDGE_INTENSE = 'intense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pkl = '/home/k1896871/Proj/gcn-master/gcn/EPIC_train_action_labels.pkl'\n",
    "with open(pkl, 'rb') as f:\n",
    "    meta = pk.load(f)\n",
    "\n",
    "    # 39596 for the whole dataset\n",
    "    # there are 28472 action segments for training\n",
    "    # 2513 unique actions\n",
    "\n",
    "    dic_participants_info = {}\n",
    "    li_activities = []\n",
    "    li_actions = []\n",
    "    tmp_participant = 'P01'\n",
    "    tmp_activity = 'P01_01'\n",
    "    for index, data in meta.iterrows():\n",
    "        v = data['verb_class']\n",
    "        n = data['noun_class']\n",
    "        vn = tuple((v,n))\n",
    "\n",
    "        participant = data['participant_id']\n",
    "        activity = data['video_id']\n",
    "\n",
    "        if tmp_activity == activity:\n",
    "            li_actions.append(vn)\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            li_activities.append(li_actions)\n",
    "            # dic_participant[activity[4:]] = li_actions\n",
    "            tmp_activity = activity\n",
    "            li_actions = []\n",
    "\n",
    "        if tmp_participant != participant:\n",
    "\n",
    "            dic_participants_info[tmp_participant] = li_activities\n",
    "            li_activities = []\n",
    "            tmp_participant = participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'P07', 'P08', 'P10', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30'])\n",
      "[  8 113   8  10 185  29 159  10  10  40   9  10  90   8  19  19   8   9\n",
      "   5   5   5   9   5   3  69  69  40  40   3  90   8 131   1   1   8   8\n",
      "  69  69  47  69  69  69  69  69  69  69  69   9   9  22  69  31  31  31\n",
      "  31  69  22 185 185   3 185   3 185 185 185 185  19 185 185  10 185  10\n",
      "  22  22  22  29  13  13  13  29  22   5  13  13  13   5  38   3  17  17\n",
      "   3  38  22  90  90  16  16   8  16   8  23   8  23  29  29  29  29  11\n",
      "  29   4   4   9   9   9   9  18  18  22  90  29  10  29  10  22  90 131\n",
      " 131  40  40 131  40  40  40  40 131  40 131 131  40  22  90   8   1   1\n",
      "  47  38  17  17  38  24  24  24  24  22  19  13  19  90  90  31  31  31\n",
      "   9   7  31  31  17  31   7  31  22  90  47  90  90  90  22   8   8   8\n",
      "  44  44  44  22  90  90  22 159   5 159  29 159  29  90  22  29  29  29\n",
      "  29  22  90  44  44  44  20  20   8  44  90  22  28  78  17  78  28  75\n",
      "   8  75   9  22  90  90  90  44  22   7  16  16  16   9  22  90  22  29\n",
      "  29  29  29  29  22  44  90  90  22  90  44  22  22  22  90   7  44  44\n",
      "   7   8  61  16  17  17  28  16  22  90  90  22  22  44  22   7  44  44\n",
      "   7  47   1   1  44  44  61  44   1  61  22  22  90  22 155 155 155 155\n",
      "  22  44  44  44  44  47  44  44  44  22 155 155  29  22  44  44  44  44\n",
      "  44  29  22   4   4  22  44  44  44  44  44  22   1   3   1   1  61   3\n",
      "   4   4]\n"
     ]
    }
   ],
   "source": [
    "p_keys = dic_participants_info.keys()\n",
    "graphs = []\n",
    "print(p_keys)\n",
    "for p_id in p_keys:\n",
    "    activity_list = dic_participants_info[p_id]\n",
    "    \n",
    "    for actions in activity_list:\n",
    "      \n",
    "        ns = np.array(actions)[:,1]\n",
    "\n",
    "        print (ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])}\n",
      "{'intense': tensor([ 1.,  1.,  1.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,\n",
      "         1.,  1.,  1.,  2.,  2.,  1.,  1.,  1.,  9.,  1.,  5.,  1.,  1.,  1.,\n",
      "         1.,  4.,  1.,  3.,  1.,  1.,  1.,  1.,  4.,  3.,  1.,  1.,  6.,  1.,\n",
      "         1.,  1.,  5.,  2.,  2.,  1.,  1.,  2.,  2.,  6.,  3.,  1.,  4.,  1.,\n",
      "         5.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  1.,  1., 13.,  9.,  1.,\n",
      "         3.,  2.,  1.,  2.,  1.,  1., 10.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,\n",
      "         1.,  1.,  2.,  1.,  1.,  2.,  4.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  8.,  1.,  2., 20.,  6.,  1.,  1.,  1.,  2.,  1.,  3.,\n",
      "         1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,\n",
      "         1.,  1.,  5.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  2.,  1.,  2.,  4.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.])}\n"
     ]
    }
   ],
   "source": [
    "# initial Graph\n",
    "G = dgl.DGLGraph(multigraph=True)\n",
    "num_node = ns.size\n",
    "G.add_nodes(NUM_EPIC_NOUN_CLASS,{'x':th.zeros((NUM_EPIC_NOUN_CLASS,5))})\n",
    "print(G.ndata)\n",
    "u = ns[0]\n",
    "# print(ns.size) 326 actions in P0101 so 175 links should be fine, as there may be only 175 unique nodes\n",
    "\n",
    "# next_ns = np.zeros(ns.size-1, dtype=np.int32)\n",
    "# next_ns[0:] = ns[1:]\n",
    "# print(next_ns)\n",
    "# G.add_edges(ns[:-1],next_ns,{'intense':th.ones(num_node-1)})\n",
    "for i in range(1,num_node):\n",
    "    v = ns[i]\n",
    "#     print(u,v)\n",
    "    if not G.has_edge_between(u,v):\n",
    "       \n",
    "        G.add_edges(u,v,{KEY_EDGE_INTENS:th.ones([1])})\n",
    "    else:\n",
    "        \n",
    "        G.edges[u,v].data[KEY_EDGE_INTENS] += 1 \n",
    "        \n",
    "    u = v\n",
    "print(G.edata)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
